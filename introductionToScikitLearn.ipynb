{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Scikit-Learn (sklearn)\n",
    "\n",
    "This notebook demonstrates some of the most useful functions of  beautiful Scikit-learn library\n",
    "\n",
    "What we're going to cover:\n",
    "\n",
    "0. An end-to-end sklearn workflow\n",
    "1. Getting the data ready\n",
    "2. Choose the right estimators/algorithm for our problems\n",
    "3. Fit the model/algorithm & use it to make predictions on our data\n",
    "4. Evaluating a model\n",
    "5. Improve a model\n",
    "6. Save and load a trained model\n",
    "7. Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. An end-to-end sklearn workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. Get the data ready\n",
    "import pandas as pd\n",
    "heartDisease = pd.read_csv('data/heart-disease.csv')\n",
    "heartDisease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X(feature matrix)\n",
    "X = heartDisease.drop('target', axis=1)\n",
    "\n",
    "# Create Y(labels)\n",
    "y = heartDisease.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create the right model and hyerparamenters\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# we will keep default hyperparameters\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Fit the model to the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(XTrain, yTrain);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "ylabel = clf.predict(np.array([0, 2, 3, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = clf.predict(XTest)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4, Evaluate the model on training data and test data\n",
    "clf.score(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(XTest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(classification_report(yTest, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(yTest, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(yTest, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Improve a model\n",
    "# Try different amount of n_estimators\n",
    "np.random.seed(42)\n",
    "for i in range(20, 120, 50):\n",
    "    print(f\"Trying classifier for {i} \") \n",
    "    clf = RandomForestClassifier(n_estimators=i).fit(XTrain, yTrain)\n",
    "    print(f\"Model accouracy on test set:{clf.score(XTest, yTest) * 100:.2f}%\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Save the model and load it\n",
    "import pickle\n",
    "\n",
    "pickle.dump(clf, open(\"models/randomForestModel.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(\"models/randomForestModel.pkl\", \"rb\"))\n",
    "loaded_model.score(XTest, yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting data ready to be used with M/L\n",
    "\n",
    "There are 3 main things, we need to do:\n",
    "    \n",
    "    1. Split the data into features and labels usually 'X's & 'y's\n",
    "    2. Filling or disregarding missing values\n",
    "    3. Converting non-numerical values to numerical values(also called feature encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heartDisease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = heartDisease.drop(\"target\", axis=1) # Axis 1=age,sex, cp,trestbps,chol, fbs, restecg, thalach, exang, oldpeak, slope, ca,thal\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = heartDisease.target\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X,\n",
    "                                                y,\n",
    "                                                test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain.shape, XTest.shape, yTrain.shape, yTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape[0] * 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "242 + 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(heartDisease)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Make sure its all numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carSales = pd.read_csv(\"data/car-sales-extended.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carSales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carSales.Doors.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(carSales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carSales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X/y\n",
    "X = carSales.drop(\"Price\", axis=1)\n",
    "y = carSales.Price\n",
    "\n",
    "# Spit into training and test\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X,\n",
    "                                               y,\n",
    "                                               test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build M/L model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(XTrain, yTrain)\n",
    "model.score(XTest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try and convert our data to numbers\n",
    "# Turn the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categoricalFeatures = [\"Make\", \"Colour\",\"Doors\"]\n",
    "oneHot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"oneHot\",\n",
    "                                oneHot,\n",
    "                                 categoricalFeatures)],\n",
    "                               remainder=\"passthrough\")\n",
    "transformedX = transformer.fit_transform(X)\n",
    "transformedX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(transformedX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(carSales[[\"Make\", \"Colour\", \"Doors\"]])\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's refit the model\n",
    "np.random.seed(42)\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(transformedX,\n",
    "                                               y,\n",
    "                                               test_size = 0.2)\n",
    "\n",
    "model.fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(XTest, yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 What if there were missing values?\n",
    "\n",
    "1. Fill them with some value (also known as imputation).\n",
    "2. Remove samples with missing data altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import carSales missing data\n",
    "carSalesMissing = pd.read_csv(\"data/car-sales-extended-missing-data.csv\")\n",
    "carSalesMissing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carSalesMissing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X & y\n",
    "X = carSalesMissing.drop(\"Price\", axis= 1)\n",
    "y = carSalesMissing.Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try and convert our data to numbers\n",
    "# Turn the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categoricalFeatures = [\"Make\", \"Colour\",\"Doors\"]\n",
    "oneHot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"oneHot\",\n",
    "                                oneHot,\n",
    "                                 categoricalFeatures)],\n",
    "                               remainder=\"passthrough\")\n",
    "transformedX = transformer.fit_transform(X)\n",
    "transformedX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carSalesMissing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1: Fill missing data with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carSalesMissing.Doors.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the 'Make' column\n",
    "carSalesMissing.Make.fillna(\"missing\", inplace=True)\n",
    "\n",
    "# Fill the \"Colour\" column \n",
    "carSalesMissing.Colour.fillna(\"missing\", inplace=True)\n",
    "\n",
    "# Fill the \"Odometer (KM)\" column\n",
    "carSalesMissing[\"Odometer (KM)\"].fillna(carSalesMissing[\"Odometer (KM)\"].mean(), inplace=True)\n",
    "\n",
    "# Fill the \"Doors column\"\n",
    "carSalesMissing.Doors.fillna(4, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkout data frame again\n",
    "carSalesMissing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carSalesMissing.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carSalesMissing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(carSalesMissing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = carSalesMissing.drop(\"Price\", axis=1)\n",
    "y = carSalesMissing.Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try and convert our data to numbers\n",
    "# Turn the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categoricalFeatures = [\"Make\", \"Colour\",\"Doors\"]\n",
    "oneHot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"oneHot\",\n",
    "                                oneHot,\n",
    "                                 categoricalFeatures)],\n",
    "                               remainder=\"passthrough\")\n",
    "transformedX = transformer.fit_transform(X)\n",
    "transformedX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Fill missing values with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carSalesMissing = pd.read_csv(\"data/car-sales-extended-missing-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carSalesMissing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "carSalesMissing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows with no labels\n",
    "carSalesMissing.dropna(subset=[\"Price\"], inplace=True)\n",
    "carSalesMissing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X & y\n",
    "X = carSalesMissing.drop(\"Price\", axis=1)\n",
    "y = carSalesMissing.Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with Scikit-Learn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Fill categorical values with 'missing' & numerical values with mean\n",
    "catImputer = SimpleImputer(strategy='constant', fill_value=\"missing\")\n",
    "doorImputer = SimpleImputer(strategy='constant', fill_value=4)\n",
    "numImputer= SimpleImputer(strategy='mean')\n",
    "\n",
    "# Define Columns\n",
    "catFeatures = ['Make', 'Colour']\n",
    "doorFeature = [\"Doors\"]\n",
    "numFeatures = [\"Odometer (KM)\"]\n",
    "\n",
    "# Create an imputer (something that fills missing data)\n",
    "imputer = ColumnTransformer([\n",
    "    (\"catImputer\", catImputer, catFeatures),\n",
    "    (\"doorImputer\", doorImputer, doorFeature),\n",
    "    (\"numImputer\", numImputer, numFeatures)\n",
    "])\n",
    "\n",
    "# Transform the data\n",
    "filledX = imputer.fit_transform(X)\n",
    "filledX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "carSalesFilled = pd.DataFrame(filledX,\n",
    "                             columns=[\"Make\", \"Colour\", \"Doors\", \"Odometer (KM)\"])\n",
    "carSalesFilled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carSalesFilled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try and convert our data to numbers\n",
    "# Turn the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categoricalFeatures = [\"Make\", \"Colour\",\"Doors\"]\n",
    "oneHot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"oneHot\",\n",
    "                                oneHot,\n",
    "                                 categoricalFeatures)],\n",
    "                               remainder=\"passthrough\")\n",
    "transformedX = transformer.fit_transform(carSalesFilled)\n",
    "transformedX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we 've' got our data as numbers and filled (no missing values)\n",
    "# Let's fit the model\n",
    "np.random.seed(42)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(transformedX,\n",
    "                                               y,\n",
    "                                               test_size = 0.2)\n",
    "model = RandomForestRegressor()\n",
    "model.fit(XTrain, yTrain)\n",
    "model.score(XTest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(carSalesFilled), len(carSales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Choosing the right estimator/algorithm for our problem\n",
    "\n",
    "Scikit-learn uses estimator as another term for machine learning model or algorithm\n",
    "\n",
    "* Classification - predicting whether sample is one thing or another\n",
    "* Regression - predicting a number\n",
    "\n",
    "Step 1- Check the Scikit-Learn machine learning map... https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Picking a m/l model for a regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Boston housing dataset\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "boston;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bostonDf = pd.DataFrame(boston[\"data\"], columns=boston[\"feature_names\"])\n",
    "bostonDf[\"target\"] = pd.Series(boston[\"target\"])\n",
    "bostonDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many samples?\n",
    "len(bostonDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try the Ridge Regression model\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data \n",
    "X = bostonDf.drop(\"target\", axis=1)\n",
    "y = bostonDf.target\n",
    "\n",
    "# Split into train and test sets\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X,\n",
    "                                               y, \n",
    "                                               test_size=0.2)\n",
    "\n",
    "# Instantiate the Ridge model\n",
    "model = Ridge()\n",
    "model.fit(XTrain, yTrain)\n",
    "\n",
    "# Check the score of Ridge model on test data\n",
    "model.score(XTest, yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we improve score?\n",
    "\n",
    "What if Ridge wasn't working?\n",
    "\n",
    "Let's refer back to map... https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try Random Forest Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = bostonDf.drop(\"target\", axis=1)\n",
    "y = bostonDf.target\n",
    "\n",
    "# Split the data\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X,\n",
    "                                               y, \n",
    "                                               test_size=0.2)\n",
    "\n",
    "# Instantiate the Random Forest Regressor\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "rf.fit(XTrain, yTrain)\n",
    "\n",
    "# Check the score of Ridge model on test data\n",
    "rf.score(XTest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Ridge model again\n",
    "model.score(XTest, yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Choosing and estimator for classification problem\n",
    "\n",
    "Let's go to the map...https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heartDisease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(heartDisease)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consulting the map and it says to try `LinearSVC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the LinarSVC estimator class\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Setup the random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make the data\n",
    "X = heartDisease.drop(\"target\", axis=1)\n",
    "y = heartDisease.target\n",
    "\n",
    "# Split the data\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X,\n",
    "                                               y,\n",
    "                                               test_size=0.2)\n",
    "\n",
    "# Instantiate LinearSVC\n",
    "clf = LinearSVC(max_iter=10000)\n",
    "clf.fit(XTrain, yTrain)\n",
    "\n",
    "# Evaluate the LinearSVC\n",
    "clf.score(XTest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heartDisease.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the `RandomForestClassifier` estimator class\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup the random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make the data\n",
    "X = heartDisease.drop(\"target\", axis=1)\n",
    "y = heartDisease.target\n",
    "\n",
    "# Split the data\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X,\n",
    "                                               y,\n",
    "                                               test_size=0.2)\n",
    "\n",
    "# Instantiate RandomForesrtClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(XTrain, yTrain)\n",
    "\n",
    "# Evaluate the RandomForestClassifier\n",
    "clf.score(XTest, yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Titbit:\n",
    "\n",
    "    1. If you have structured data, use ensemble methods\n",
    "    2. If youu have unstructured data, use Deeplearning or trasfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heartDisease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit the model/ algorithm on our data and use it to make predictions\n",
    "\n",
    "### 3.1 Fitting the model to the data\n",
    "\n",
    "Different names for\n",
    "* `X` = features, feature variables, data\n",
    "* `y` = labels, targets, target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the `RandomForestClassifier` estimator class\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup the random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make the data\n",
    "X = heartDisease.drop(\"target\", axis=1)\n",
    "y = heartDisease.target\n",
    "\n",
    "# Split the data\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X,\n",
    "                                               y,\n",
    "                                               test_size=0.2)\n",
    "\n",
    "# Instantiate RandomForesrtClassifier\n",
    "clf = RandomForestClassifier()\n",
    "print(clf)\n",
    "# Fit the model to the data(training machine learning model)\n",
    "clf.fit(XTrain, yTrain)\n",
    "\n",
    "# Evaluate the RandomForestClassifier(use the patterns the model has learned)\n",
    "clf.score(XTest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(), X.tail(), y.head(), y.tail() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest model Deepdive\n",
    "\n",
    "Resources for Random Forest Models\n",
    "\n",
    "* [Random Forest Wikipedia][1]\n",
    "\n",
    "* [Random Forest in python][2] by yhat\n",
    "\n",
    "* [An Implementation and Explanation of the Random Forest in Python][3]\n",
    "\n",
    "[1]:https://en.wikipedia.org/wiki/Random_forest\n",
    "[2]:http://blog.yhat.com/posts/random-forests-in-python.html#:~:text=by%20yhat%20%7C%20June%205%2C%202013&text=Random%20forest%20is%20capable%20of,about%20random%20forests%20using%20Python\n",
    "[3]:https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76\n",
    "\n",
    "### 3.2 Make predictions using a machine learning model\n",
    "2 ways to make predictions:\n",
    "  1. `predict()`\n",
    "  2. `predict_proba()`\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a trained model to make predictions\n",
    "clf.predict(np.array([1, 7, 8, 3, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(XTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare prediction to truth labels to evaluate the model\n",
    "yPreds = clf.predict(XTest)\n",
    "np.mean(yPreds == yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(XTest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(yTest, yPreds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions with `predict_proba()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_proba() returns probabilities of classification label\n",
    "clf.predict_proba(XTest[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's predict() on same data...\n",
    "clf.predict(XTest[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heartDisease.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`predict()` can also be used in regreesion models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bostonDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create data\n",
    "X = bostonDf.drop('target', axis=1)\n",
    "y = bostonDf.target\n",
    "\n",
    "# Split into X and y\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X,\n",
    "                                                y,\n",
    "                                                test_size=0.2)\n",
    "\n",
    "# Instantiate and fit the model\n",
    "model = RandomForestRegressor().fit(XTrain, yTrain)\n",
    "\n",
    "# Make predictions\n",
    "yPreds = model.predict(XTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPreds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(yPreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the predictions to the truth\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mean_absolute_error(yTest, yPreds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluating a m/l Model\n",
    "\n",
    "There are 3 ways to evaluate Scikit-Learn models/estimators:\n",
    "\n",
    "1. Estimator `score` method\n",
    "2. `Scoring` parameter\n",
    "3. Metric functions\n",
    "\n",
    "### 4.1 Evaluating with estimating `score` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heartDisease.drop(\"target\", axis=1)\n",
    "y = heartDisease.target\n",
    "\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X,\n",
    "                                                y,\n",
    "                                                test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "clf.fit(XTrain, yTrain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(XTest, yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do same but for regression... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create data\n",
    "X = bostonDf.drop('target', axis=1)\n",
    "y = bostonDf.target\n",
    "\n",
    "# Split into X and y\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X,\n",
    "                                                y,\n",
    "                                                test_size=0.2)\n",
    "\n",
    "# Instantiate and fit the model\n",
    "model = RandomForestRegressor().fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(XTest, yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Evaluating a model using `scoring` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heartDisease.drop(\"target\", axis=1)\n",
    "y = heartDisease.target\n",
    "\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X,\n",
    "                                                y,\n",
    "                                                test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "clf.fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(XTest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(clf, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(clf, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Single training and test split score\n",
    "clfSingleScore = clf.score(XTest, yTest)\n",
    "\n",
    "# Take the mean of 5 cross-val scores\n",
    "clfCrossValScore = (np.mean(cross_val_score(clf, X, y, cv=5)))\n",
    "\n",
    "# Compare the two\n",
    "clfSingleScore, clfCrossValScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default scoring parameter of classifier = mean accuracy\n",
    "clf.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring parameter set to None by default\n",
    "cross_val_score(clf, X, y, cv=5, scoring=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Classification model evaluation metrics\n",
    "\n",
    "1. Accuracy\n",
    "2. Area under ROC curve\n",
    "3. Confusion matrix\n",
    "4. Classification report\n",
    "\n",
    "**Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heartDisease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heartDisease.drop(\"target\", axis=1)\n",
    "y = heartDisease.target\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "CrossValScore = cross_val_score(clf, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.mean(CrossValScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Heart Disease Classifier Cross-Validated Accuracy:{c * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Area under the reciever operating curve(AUC/ROC)**\n",
    "* Area under curve(AUC)\n",
    "* ROC curve\n",
    "\n",
    "RIC curve are a comparison of a model's true positive rate(tpr) vs a model's false positive rate(fpr)\n",
    "\n",
    "* True positive = model predicts 1 when truth is 1\n",
    "* False positive = model predicts 1 when truth is 0\n",
    "* True negative = model predicts 0 when truth is 0\n",
    "* False negative = model predicts 0 when truth is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create XTest..., etc\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X,\n",
    "                                                y,\n",
    "                                                test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Fit the clssifier\n",
    "clf.fit(XTrain, yTrain)\n",
    "\n",
    "# Make predictions with probabilities\n",
    "yProb = clf.predict_proba(XTest)\n",
    "yProb[:10], len(yProb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yProbPositive = yProb[:, 1]\n",
    "yProbPositive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yProbPositive[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate fpr, tpr and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(yTest, yProbPositive)\n",
    "\n",
    "# Check the false positive rates\n",
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function for plotting ROC curves\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotRocCurve(fpr, tpr):\n",
    "    \"\"\"\n",
    "    Plot a ROC curve given the false positive rate (fpr) and true positive rate(tpr) \n",
    "    \"\"\"\n",
    "    \n",
    "    # Plot roc curve\n",
    "    plt.plot(fpr, tpr,color=\"orange\", label=\"ROC\")\n",
    "    # Plot line with no predictive power(baseline)\n",
    "    plt.plot([0,1], [0,1], color=\"darkblue\", linestyle=\"--\", label=\"Guesing\")\n",
    "    \n",
    "    # Customise the plot\n",
    "    plt.xlabel(\"False Positive Rate (fpr)\")\n",
    "    plt.ylabel(\"True Positive Rate (tpr)\")\n",
    "    plt.title(\"ROC curve\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plotRocCurve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(yTest, yProbPositive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot perfect ROC curve and AUC score\n",
    "fpr, tpr, thresholds = roc_curve(yTest, yTest)\n",
    "plotRocCurve(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfect AUC Score\n",
    "roc_auc_score(yTest, yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**\n",
    "\n",
    "A confusion matrix is a quick way to compare the label a model predicts and actual label it was supposed to predict\n",
    "\n",
    "In essence, giving you an idea of where the model is getting confused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "yPreds = clf.predict(XTest)\n",
    "\n",
    "confusion_matrix(yTest, yPreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix with pd.crosstab()\n",
    "pd.crosstab(yTest,\n",
    "           yPreds,\n",
    "           rownames=[\"Actual Labels\"],\n",
    "           colnames=[\"Predicted Labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "24 + 5 + 4 + 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How to install a conda package into current environment from Jupyter notebook?\n",
    "import sys\n",
    "!conda install -y --prefix {sys.prefix} seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make our confusion matrix more visual with Seaborn's heatmap()\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the font scale\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "# Create confusion matrix\n",
    "confMat = confusion_matrix(yTest, yPreds)\n",
    "\n",
    "# Plot it using seaborn heatmap\n",
    "sns.heatmap(confMat);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotConfMat(confMat):\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix using Seaborn's heatmap()\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    ax = sns.heatmap(confMat,\n",
    "                    annot=True, # Annotate the box with confMat info\n",
    "                    cbar=False)\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\");\n",
    " \n",
    "plotConfMat(confMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(clf, X, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(yTest, yPreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where precision and recall become valuable\n",
    "diseaseTrue = np.zeros(10000)\n",
    "diseaseTrue[0] = 1 # only one positibe case\n",
    "\n",
    "diseasePreds = np.zeros(10000) # model predicts every case as O\n",
    "\n",
    "\n",
    "pd.DataFrame(classification_report(diseaseTrue,\n",
    "                                  diseasePreds,\n",
    "                                  output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize classification metrics:\n",
    "    \n",
    "   * **Accuracy**: is a good measure to start with if all classes are balanced(e.g. same amount of samples which are labelled with 0 or 1).\n",
    "   * **Precision** and **recall** become more important when classes are imbalanced.\n",
    "   * If false positves are worse than false negatives, aim for higher precision\n",
    "   * If false negatives are worse than false positives, aim for higher recall\n",
    "   * **F1-score** is a combination of precision and recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Regression model evaluation metrics\n",
    "\n",
    "Model Evaluation Metrics: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "1. R^2 (pronouned r-squared) or coefficient of determination\n",
    "2. Mean absolute error (MAE)\n",
    "3. Mean squared error (MSE)\n",
    "\n",
    "**R^2**\n",
    "\n",
    "What R-squared does:Compares your models predictions to the mean of the targets. Values can rangefrom negative infinity(a very poor model) to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = bostonDf.drop(\"target\",axis=1)\n",
    "y = bostonDf.target\n",
    "\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X,\n",
    "                                                y,\n",
    "                                                test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(XTrain, yTrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(XTest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Fill an array with yTest mean\n",
    "yTestM = np.full(len(yTest), yTest.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTest.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(yTest, yTestM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(yTest, yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean absolute error (MAE)**\n",
    "\n",
    "MAE is the average of absolute difference between predictions and actual values. It gives you an idea of how wrong your model prediction are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean absolute error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "yPreds = model.predict(XTest)\n",
    "mae = mean_absolute_error(yTest, yPreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"actual values\":yTest,\n",
    "                       \"predicted values\": yPreds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['difference'] = df['predicted values'] - df['actual values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean Squared error**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Squared error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "yPreds = model.predict(XTest)\n",
    "mse = mean_squared_error(yTest,yPreds)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE by hand\n",
    "squared = np.square(df['difference'])\n",
    "squared.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.23 Finally using the `scoring` paramter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heartDisease.drop(\"target\", axis=1)\n",
    "y = heartDisease.target\n",
    "\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "cvAcc = cross_val_score(clf, X, y, cv=5, scoring=None)\n",
    "cvAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The cross validated accuracy is: {cvAcc.mean() * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "cvAcc = cross_val_score(clf, X, y, cv=5, scoring=\"accuracy\")\n",
    "cvAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The cross validated accuracy is: {cvAcc.mean() * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision\n",
    "cvPrecision = cross_val_score(clf, X, y, cv=5, scoring=\"precision\")\n",
    "np.mean(cvPrecision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall\n",
    "cvRecall = cross_val_score(clf, X, y, cv=5, scoring=\"recall\")\n",
    "np.mean(cvRecall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvF1 = cross_val_score(clf, X, y, cv=5, scoring=\"f1\")\n",
    "np.mean(cvF1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = bostonDf.drop(\"target\", axis=1)\n",
    "y = bostonDf[\"target\"]\n",
    "\n",
    "model = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "cvR2 = cross_val_score(model, X, y, cv=5, scoring=None)\n",
    "np.mean(cvR2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "cvR2 = cross_val_score(model, X, y, cv=5, scoring=\"r2\")\n",
    "cvR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean absolute error\n",
    "cvMAE = cross_val_score(model, X, y, cv=5, scoring=\"neg_mean_absolute_error\")\n",
    "cvMAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Square error\n",
    "cvMSE = cross_val_score(model, X, y, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "np.mean(cvMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Using different evaluation metrics as Scikit-Learn functions\n",
    "\n",
    "**Classification evaluation functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heartDisease.drop('target', axis=1)\n",
    "y = heartDisease.target\n",
    "\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X,\n",
    "                                                y,\n",
    "                                                test_size=0.2)\n",
    "\n",
    "clf= RandomForestClassifier()\n",
    "clf.fit(XTrain, yTrain)\n",
    "\n",
    "# Make some predictions\n",
    "yPreds = clf.predict(XTest)\n",
    "\n",
    "# Evaluate the classifier\n",
    "print(\"Classifier metrics on test set\")\n",
    "print(f\"Accuracy:{accuracy_score(yTest, yPreds)* 100:.2f}\")\n",
    "print(f\"Precision:{precision_score(yTest, yPreds) * 100:.2f}\")\n",
    "print(f\"Recall:{recall_score(yTest, yPreds)}\")\n",
    "print(f\"F1: {f1_score(yTest, yPreds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(yPreds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regression evaluation functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_log_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = bostonDf.drop('target', axis=1)\n",
    "y = bostonDf.target\n",
    "\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X,\n",
    "                                                y,\n",
    "                                                test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(XTrain, yTrain)\n",
    "\n",
    "# Make some predictions\n",
    "yPreds = model.predict(XTest)\n",
    "\n",
    "# Evaluate the classifier\n",
    "print(\"Regression model metrics on test set\")\n",
    "print(f\"R^2: {r2_score(yTest, yPreds)}\")\n",
    "print(f\"MAE: {mean_absolute_error(yTest, yPreds)}\")\n",
    "print(f\"MSE: {mean_squared_error(yTest, yPreds)}\")\n",
    "# print(f\"F1: {f1_score(yTest, yPreds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Improving a model\n",
    "\n",
    "first predictions = baseline predictions\n",
    "first model = baseline predictions\n",
    "\n",
    "From a data perspective:\n",
    "* Could we collect more data? (generally, the more data, the better) \n",
    "* Could we improve our data? \n",
    "\n",
    "From a model perspective:\n",
    "* Is there a better model we could use?\n",
    "* Could we improve the current model? \n",
    "\n",
    "Hyperparameter vs Parameters\n",
    "* Parameter = models finds these patterns in data\n",
    "* Hyperparameter = settings on model you can adjust to improve its ability to find patterns\n",
    "\n",
    "Three ways to adjust hyperparameters:\n",
    "1. By hand\n",
    "2. Randomly with RandomSearchCV\n",
    "3. Exhaustively with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Tuning hyperparameters by hand\n",
    "\n",
    "Let's make 3 sets training, validation and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to try and adjust:\n",
    "\n",
    "* `max_depth`\n",
    "* `max_features`\n",
    "* `min_sample_leaf`\n",
    "* `min_samples_split`\n",
    "* `n_estimators`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(yTrue, yPreds):\n",
    "    \"\"\"\n",
    "    Performs evauation, comparison on yTrue labels vs yPreds labels on a classification\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(yTrue, yPreds)\n",
    "    precision = precision_score(yTrue, yPreds)\n",
    "    recall = recall_score(yTrue, yPreds)\n",
    "    f1 = f1_score(yTrue, yPreds)\n",
    "    metricDict = {\"accuracy\":round(accuracy, 2),\n",
    "                  \"precision\": round(precision, 2),\n",
    "                  \"recall\": round(recall, 2),\n",
    "                  \"f1\": round(f1,2)}\n",
    "    print(f\"Acc: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision :.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 score: {f1:.2f}\")\n",
    "\n",
    "    return metricDict;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Shuffle the data\n",
    "heartDiseaseShuffled = heartDisease.sample(frac=1)\n",
    "\n",
    "# Split into X & y\n",
    "X = heartDiseaseShuffled.drop(\"target\", axis=1)\n",
    "y = heartDiseaseShuffled.target\n",
    "\n",
    "# Split the data to train, validation & test sets\n",
    "trainSplit = round(0.7 * len(heartDiseaseShuffled))\n",
    "validsplit = round (trainSplit + 0.15 * len(heartDiseaseShuffled))\n",
    "XTrain, yTrain = X[:trainSplit], y[:trainSplit]\n",
    "XValid, yValid = X[trainSplit:validsplit], y[trainSplit:validsplit]\n",
    "XTest, yTest = X[validsplit:], y[validsplit:]\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(XTrain, yTrain)\n",
    "\n",
    "# Make baseline predictions\n",
    "yPreds = clf.predict(XValid)\n",
    "\n",
    "# Evaluate the classifier on validation set\n",
    "baselineMetrics = evaluate_preds(yValid, yPreds)\n",
    "baselineMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "clf2 = RandomForestClassifier(n_estimators=100)\n",
    "clf2.fit(XTrain, yTrain)\n",
    "\n",
    "# Make predictions \n",
    "yPreds2 = clf.predict(XValid)\n",
    "\n",
    "# Evaluate 2nd classifier\n",
    "clf2Metrics = evaluate_preds(yValid, yPreds2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Hyperparameter tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "grid = {\"n_estimators\":[10, 100, 200, 500, 1000, 1200],\n",
    "        \"max_depth\":[None, 5, 10, 20, 30],\n",
    "        \"max_features\":[\"auto\", \"sqrt\"],\n",
    "        \"min_samples_split\":[2, 4, 6],\n",
    "        \"min_samples_leaf\":[1, 2,4]\n",
    "       }\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split into X & y\n",
    "X = heartDiseaseShuffled.drop(\"target\", axis=1)\n",
    "y = heartDiseaseShuffled.target\n",
    "\n",
    "# Split into train and test sets\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X,\n",
    "                                               y,\n",
    "                                               test_size=0.2)\n",
    "\n",
    "\n",
    "# Instantiate RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Setup RandomizedSearchCV\n",
    "rsClf = RandomizedSearchCV(estimator=clf,\n",
    "                           param_distributions=grid,\n",
    "                           n_iter=10, # number of models to try\n",
    "                           cv=5,\n",
    "                           verbose=2)\n",
    "\n",
    "# Fit the RandomizedSearchcv version of clf\n",
    "rsClf.fit(XTrain, yTrain);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsClf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with the best hyperparameters\n",
    "rsYPreds = rsClf.predict(XTest)\n",
    "\n",
    "# Evaluate the predictions\n",
    "rsMetrics = evaluate_preds(yTest, rsYPreds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Hyperparameter tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid2 = {'n_estimators': [100, 200, 500],\n",
    "         'max_depth': [None],\n",
    "         'max_features': ['auto', 'sqrt'],\n",
    "         'min_samples_split': [6],\n",
    "         'min_samples_leaf': [1, 2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split into X & y\n",
    "X = heartDiseaseShuffled.drop(\"target\", axis=1)\n",
    "y = heartDiseaseShuffled.target\n",
    "\n",
    "# Split into train and test sets\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X,\n",
    "                                               y,\n",
    "                                               test_size=0.2)\n",
    "\n",
    "\n",
    "# Instantiate RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Setup GridSearchCV\n",
    "gsClf = GridSearchCV(estimator=clf,\n",
    "                     param_grid=grid2,\n",
    "                     cv=5,\n",
    "                     verbose=2)\n",
    "\n",
    "# Fit the GridSearchcv version of clf\n",
    "gsClf.fit(XTrain, yTrain);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsClf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate GridSearchCV model\n",
    "gsYpreds = gsClf.predict(XTest)\n",
    "\n",
    "# Evaluate the classifier on validation set\n",
    "gsMetrics = evaluate_preds(yTest, gsYpreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compareMetrics = pd.DataFrame({\"baseline\": baselineMetrics,\n",
    "                               \"clf2\": clf2Metrics,\n",
    "                                \"random search\": rsMetrics,\n",
    "                                \"grid search\": gsMetrics})\n",
    "\n",
    "compareMetrics.plot.bar(figsize=(10, 8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Saving and loading trained M/L models\n",
    "\n",
    "Two ways to save and load models\n",
    "1. With python's `pickle` module\n",
    "2. With the `joblib` module\n",
    "\n",
    "**Pickle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save an exisiting model to file\n",
    "pickle.dump(gsClf, open('models/gsModel.pkl', \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a saved model\n",
    "loadedPickeModel = pickle.load(open('models/gsModel.pkl', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions\n",
    "loadYPreds = loadedPickeModel.predict(XTest)\n",
    "evaluate_preds(yTest, loadYPreds);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Joblib** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "# Save the model\n",
    "dump(gsClf, filename=\"models/gsModel(1).joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a saved joblib model\n",
    "loadedJobModel = load(filename=\"models/gsModel(1).joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make and evaluate joblib predictions\n",
    "joblibYPreds = loadedJobModel.predict(XTest)\n",
    "evaluate_preds(yTest, joblibYPreds);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/car-sales-extended-missing-data.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps we need to do(all inone cell):\n",
    "1. Fill the missing data\n",
    "2. Convert data to numbers\n",
    "3. Build a model on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22188417408787875"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting data ready\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Modelling \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Setup random seed\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# Import data and drop rows with missing labels\n",
    "data = pd.read_csv(\"data/car-sales-extended-missing-data.csv\")\n",
    "data.dropna(subset=[\"Price\"], inplace=True)\n",
    "\n",
    "# Define different features and transform pipeline\n",
    "categoricalFeatures = [\"Make\", \"Colour\"]\n",
    "categoricalTransformer = Pipeline(steps=[\n",
    "    (\"imputer\",SimpleImputer(strategy=\"constant\",fill_value=\"missing\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "doorFeature = [\"Doors\"]\n",
    "doorTranformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=4))\n",
    "])\n",
    "\n",
    "numericFeatures = [\"Odometer (KM)\"]\n",
    "numericTransformer = Pipeline(steps=[\n",
    "    (\"impute\", SimpleImputer(strategy=\"mean\"))\n",
    "])\n",
    "\n",
    "# Setup preprocess steps (fill missing values, then convert to numbers)\n",
    "preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"cat\", categoricalTransformer, categoricalFeatures),\n",
    "                (\"door\",doorTranformer, doorFeature),\n",
    "                (\"num\", numericTransformer, numericFeatures)\n",
    "            ])\n",
    "\n",
    "# Creating a preproessong and modelling pipeline\n",
    "model = Pipeline(steps=[(\"preprocessor\", preprocessor),\n",
    "                       (\"model\", RandomForestRegressor())])\n",
    "\n",
    "# Split data\n",
    "X = data.drop(\"Price\", axis=1)\n",
    "y = data.Price\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X,\n",
    "                                                y,\n",
    "                                                test_size=0.2)\n",
    "\n",
    "# Fit and score the model\n",
    "model.fit(XTrain, yTrain)\n",
    "model.score(XTest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
